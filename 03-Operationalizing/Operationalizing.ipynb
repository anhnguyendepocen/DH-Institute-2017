{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>It Starts with Research Question...</h1>\n",
    "<img src='Moretti 7, Fig 7.png' width=\"66%\" height=\"66%\">\n",
    "<br>\n",
    "<img src='Moretti 7, Fig 8.png' width=\"66%\" height=\"66%\">\n",
    "<br>\n",
    "<img src='Moretti 11, excerpt.png' width=\"66%\" height=\"66%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operationalizing\n",
    "\n",
    "<ol>\n",
    "<li>Review/Preview: Strings & Lists</li>\n",
    "<li>Pandas</li>\n",
    "<li>Arithmetic!</li>\n",
    "<li>Character Space in Antigone</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Review/Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings, Lists, & List Comprehensions\n",
    "\n",
    "Strings and string methods will be our bread and butter throughout the workshop. We have already seen them assigned to variables, split over white spaces, added together, and sliced by index. Let's review those techniques and try out a couple variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's assign a string to a new variable\n",
    "# Using the triple quotation mark, we can simply paste a passage in between\n",
    "# and Python will treat it as a continuous string\n",
    "\n",
    "first_sonnet = \"\"\"From fairest creatures we desire increase,\n",
    "That thereby beauty's rose might never die,\n",
    "But as the riper should by time decease,\n",
    "His tender heir might bear his memory\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that when we print the 'first_sonnet', we see the character\n",
    "# that represents a line break: '\\n'\n",
    "\n",
    "first_sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A familiar string method\n",
    "\n",
    "first_sonnet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's assign the plain list of tokens to a variable\n",
    "\n",
    "sonnet_tokens = first_sonnet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And find out how many words there are in that quatrain\n",
    "\n",
    "len(sonnet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's pull out the tokens from the second line\n",
    "\n",
    "sonnet_tokens[6:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How long is each word in sonnet tokens?\n",
    "\n",
    "[len(token) for token in sonnet_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And why not assign that to a variable...\n",
    "\n",
    "token_lengths = [len(token) for token in sonnet_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... so we can do something fun, like get the average word length\n",
    "\n",
    "sum(token_lengths) / len(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. Retrieve the word 'thereby' from the list of 'sonnet_tokens' by calling its index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending our Methods\n",
    "\n",
    "Beyond a simple list, we often find it useful to organize information into lists of lists. That is, a list in which each entry is itself a list of elements. For example, we may not want to treat a poem as a flat list of words but instead would like to group words into their constitutive lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There's a twist!\n",
    "\n",
    "first_sonnet.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign the list of whole lines to a new variable\n",
    "sonnet_lines = first_sonnet.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How long is this list?\n",
    "\n",
    "len(sonnet_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of lists!\n",
    "\n",
    "[line.split() for line in sonnet_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign this to a variable\n",
    "\n",
    "tokens_by_line = [line.split() for line in sonnet_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check its length\n",
    "\n",
    "len(tokens_by_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull out the second line\n",
    "\n",
    "tokens_by_line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How long is that second line?\n",
    "\n",
    "len(tokens_by_line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull up an individual word\n",
    "\n",
    "tokens_by_line[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. Retrieve the word 'thereby' from the list of 'tokens_by_line' by calling its indices.\n",
    "\n",
    "## EX. Find the average number of words per line in 'tokens_by_line'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pandas\n",
    "\n",
    "We've started to grapple with the weirdly complicated idea of lists of lists and their utility for textual study. In fact, these translate rather easily into the very familiar idea of the spreadsheet. Very often, our data (whether number or text) can be represented as rows and columns. Once in that format, many mathematical operations come naturally.\n",
    "\n",
    "<i>Pandas</i> is a popular and flexible package whose primary use is its datatype: the <i>DataFrame</i>. The dataframe is essentially a spreadsheet, like you would find in Excel, but it integrates seamlessly into a Natural Language Processing workflow and it has a few tricks up its sleeve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get ready!\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of three sub-lists, each with three entries\n",
    "\n",
    "square_list = [[1,2,3],[4,5,6],[7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's slice it by row\n",
    "# Note that we would have to do some acrobatics in order to slice by column!\n",
    "\n",
    "square_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from that list\n",
    "\n",
    "pandas.DataFrame(square_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a couple of lists for our column and row labels\n",
    "\n",
    "column_names = ['Eggs', 'Bacon', 'Sausage']\n",
    "row_names = ['Served','With','Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A-ha!\n",
    "\n",
    "pandas.DataFrame(square_list, columns = column_names, index=row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign this to a variable\n",
    "\n",
    "spam_df = pandas.DataFrame(square_list, columns = column_names, index=row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call up a column of the dataframe\n",
    "\n",
    "spam_df['Eggs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make that column into a list\n",
    "\n",
    "list(spam_df['Eggs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the indices for the entries in the column\n",
    "\n",
    "spam_df['Eggs'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call up a row from the indices\n",
    "\n",
    "spam_df.loc['Served']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call up a couple of rows, using a list of indices!\n",
    "\n",
    "spam_df.loc[['Spam','Served']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a specific entry by calling both row and column\n",
    "\n",
    "spam_df.loc['Spam']['Eggs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Temporarily re-order the dataframe by values in the 'Eggs' column\n",
    "\n",
    "spam_df.sort_values('Eggs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new column\n",
    "\n",
    "spam_df['Lobster Thermidor aux crevettes'] = [10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect\n",
    "\n",
    "spam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. Call up the entries (5 and 6) from the middle of the dataframe 'spam_df' individually\n",
    "\n",
    "## CHALLENGE: Call up both entries at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Slice out a column\n",
    "\n",
    "spam_df['Bacon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate whether each element in the column is greater than 5\n",
    "\n",
    "spam_df['Bacon']==5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use that evaluation to subset the table\n",
    "\n",
    "spam_df[spam_df['Bacon']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. Slice 'spam_df' to contain only rows in which 'Sausage' is greater than 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Arithmetic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our dataframe\n",
    "\n",
    "spam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas will produce a few descriptive statistics for each row\n",
    "\n",
    "spam_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply entries of the dataframe by 10\n",
    "\n",
    "spam_df*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add 10 to each entry\n",
    "\n",
    "spam_df+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Of course our dataframe hasn't changed\n",
    "\n",
    "spam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What if we just want to add the values in the column?\n",
    "\n",
    "sum(spam_df['Bacon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also perform operations among columns\n",
    "# Pandas knows to match up individual entries in each column\n",
    "\n",
    "spam_df['Bacon']/spam_df['Eggs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Character Space in Antigone\n",
    "\n",
    "In Moretti's study, he offers several measures of the concept of <i>character</i>. The simplest of these is to measure the relative dialogue belong to each character in a play. Presumably the main characters will speak more and peripheral characters will speak less.\n",
    "\n",
    "The statistical moves we will make here are not only counting the raw number of words spoken by each character but also normalizing them. That is, converting them into a fraction of all words in the play.\n",
    "\n",
    "In order to focus on the statistical tasks at hand, we will begin by importing a spreadsheet in which each row is labeled with an individual character's name. Its columns contain metadata about the character herself, as well as a single column containing all of her dialogue as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read spreadsheet from the hard drive\n",
    "\n",
    "dialogue_df = pandas.read_csv('antigone_dialogue.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look\n",
    "\n",
    "dialogue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pulling out a single column acts like a list -- with labels\n",
    "\n",
    "dialogue_df['NAMED_CHARACTER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If we wish, we can use metadata to subset our dataframe\n",
    "\n",
    "dialogue_df[dialogue_df['NAMED_CHARACTER']=='named']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out the first element of the dialogue list\n",
    "\n",
    "dialogue_df['DIALOGUE'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of lists; split each character's dialogue into a list of tokens\n",
    "\n",
    "dialogue_tokens = [character.split() for character in dialogue_df['DIALOGUE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A list of lists!\n",
    "\n",
    "dialogue_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many tokens are in each list?\n",
    "\n",
    "dialogue_len = [len(tokens) for tokens in dialogue_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the numbers of tokens per character\n",
    "\n",
    "dialogue_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign this as a new column in the dataframe\n",
    "\n",
    "dialogue_df['WORDS_SPOKEN'] = dialogue_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's visualize!\n",
    "\n",
    "# Tells Jupyter to produce images in notebook\n",
    "% pylab inline\n",
    "\n",
    "# Makes images look good\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize using the 'plot' method from Pandas\n",
    "\n",
    "dialogue_df['WORDS_SPOKEN'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##     Moretti had not simply plotted the number words spoken by each character\n",
    "##     but the percentage of all words in the play belonging to that character.\n",
    "##     He also had sorted the columns of his diagram by their height.\n",
    "\n",
    "## EX. Calculate the share of each character's dialogue as a percentage of the total\n",
    "##     number of words in the play.\n",
    "\n",
    "## EX. Reorganize the dataframe such that these percentages appear in descending order.\n",
    "\n",
    "## EX. Visualize the ordered share of each character's dialogue as a bar chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Transform Dramatic Text into Charcter-CSV\n",
    "\n",
    "This script uses a data type, a method, and an operation that are all closely related to ones that we've seen. The <i>dictionary</i> resembles a <i>list</i> or a <i>DataFrame</i>. The string-method <i>index</i> sort of reverse engineers our slicing method where we had called up specific characters from a string by their index.\n",
    "The <i>for-loop</i> bears a close resemblence to the <i>list comprehension</i>, although it doesn't necessarily produce a list.\n",
    "\n",
    "Try playing around with them to see what they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the text of Antigone from a file on your hard drive\n",
    "antigone_text = open('antigone.txt', 'r').read()\n",
    "\n",
    "# Create a list by splitting the string whereever a double line break occurs\n",
    "antigone_list = antigone_text.split('\\n\\n')\n",
    "\n",
    "# Create a new, empty dictionary\n",
    "dialogue_dict = {}\n",
    "\n",
    "# Iterate through each of the play's lines\n",
    "for line in antigone_list:\n",
    "    \n",
    "    # Find the first space in each line\n",
    "    index_first_space = line.index(' ')\n",
    "    \n",
    "    # Slice the line, preceding the first space\n",
    "    character_name = line[:index_first_space]\n",
    "    \n",
    "    # Check whether the character is in our dictionary yet\n",
    "    if character_name not in dialogue_dict.keys():\n",
    "        \n",
    "        # If not, create a new entry whose value is a slice of the line *after* the first space\n",
    "        dialogue_dict[character_name] = line[index_first_space:]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # If so, add the slice of line to the existing value\n",
    "        dialogue_dict[character_name] = dialogue_dict[character_name] + line[index_first_space:]\n",
    "        \n",
    "# Get ready!\n",
    "import pandas\n",
    "\n",
    "# Convert dictionary to DataFrame; instruct pandas that each dictionary entry is a row ('index')\n",
    "dialogue_df = pandas.DataFrame.from_dict(dialogue_dict, orient='index')\n",
    "\n",
    "# Add label to spreadsheet column\n",
    "dialogue_df.columns = ['DIALOGUE']\n",
    "\n",
    "# Export as csv; save to hard drive\n",
    "dialogue_df.to_csv('antigone_dialogue_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. The text of Hamlet is also contained within the folder for this notebook ('hamlet.txt').\n",
    "##     Perform Moretti's character space analysis on that play.\n",
    "\n",
    "##     Note that the dialogue is formatted slightly differently in our copy of Hamlet than it\n",
    "##     was in Antigone. This means that you will need to tweak the script above if you wish\n",
    "##     to use it for Hamlet. In reality it is very often the case that a script has to be\n",
    "##     tailored to different applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
